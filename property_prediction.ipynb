{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T03:20:32.267293Z",
     "start_time": "2025-09-18T03:20:32.257032Z"
    }
   },
   "source": [
    "# achieve property prediction using machine learning,\n",
    "# When achieve predicting task for a property, only select data with that property measured (Non-NaN) \n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:21:38.931422Z",
     "start_time": "2025-09-18T03:21:29.754938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ],
   "id": "d8bb8bb7fe66e153",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:22:16.369421Z",
     "start_time": "2025-09-18T03:22:16.146232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('datasets/Formula/processed_formula_property_data.csv') \n",
    "data"
   ],
   "id": "5e3fcec45571d487",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       FID  Property_1  Property_2  Property_3  Property_4  Property_5  \\\n",
       "0        1         NaN         NaN    0.187732         NaN         NaN   \n",
       "1        2         NaN         NaN    0.167026         NaN         NaN   \n",
       "2        3         NaN         NaN    0.207747         NaN         NaN   \n",
       "3        4         NaN         NaN    0.318178         NaN         NaN   \n",
       "4        5         NaN         NaN    0.314727         NaN         NaN   \n",
       "...    ...         ...         ...         ...         ...         ...   \n",
       "9905  5507    0.253754    0.300485    0.247778    0.268624    0.226766   \n",
       "9906  5508         NaN         NaN         NaN         NaN         NaN   \n",
       "9907  5509         NaN         NaN         NaN         NaN         NaN   \n",
       "9908  5510         NaN         NaN         NaN         NaN         NaN   \n",
       "9909  5511    0.036348    0.132472    1.000000    1.000000    0.837051   \n",
       "\n",
       "      Property_6  Property_7  Property_8  Property_9  ...  Formula_PC29  \\\n",
       "0            NaN    0.192958         NaN         NaN  ...      0.630510   \n",
       "1            NaN    0.178770         NaN         NaN  ...      0.626488   \n",
       "2            NaN    0.172320         NaN         NaN  ...      0.625965   \n",
       "3            NaN    0.430285         NaN         NaN  ...      0.944698   \n",
       "4            NaN    0.418935         NaN         NaN  ...      0.962751   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "9905    0.368019    0.552818    0.244909    0.681583  ...     -0.013889   \n",
       "9906         NaN         NaN         NaN         NaN  ...     -0.098897   \n",
       "9907         NaN         NaN         NaN         NaN  ...     -0.328240   \n",
       "9908         NaN         NaN         NaN         NaN  ...      0.233434   \n",
       "9909    0.871392    0.683864    0.012909    0.622790  ...     -1.788210   \n",
       "\n",
       "      Formula_PC30  Formula_PC31  Formula_PC32  Formula_PC33  Formula_PC34  \\\n",
       "0        -1.044794     -1.010974      0.784127     -0.785801      0.434642   \n",
       "1        -1.039497     -1.011796      0.781721     -0.779595      0.437224   \n",
       "2        -1.040429     -1.009537      0.782721     -0.782244      0.433595   \n",
       "3        -0.966308     -1.208546      1.190928     -0.231057      1.037499   \n",
       "4        -0.445088     -1.135749      0.909521      0.174548      1.176918   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9905      0.703369     -0.138177      0.232650      0.012936     -0.055710   \n",
       "9906      1.631745     -0.126407      0.355267      0.879366      0.325944   \n",
       "9907     -1.108290      0.176624     -1.003014      0.223545     -0.215317   \n",
       "9908     -0.102092      0.146241     -1.154091      0.553121      0.201320   \n",
       "9909     -0.360862     -1.356307      0.766919     -1.876464     -1.106856   \n",
       "\n",
       "      Formula_PC35  Condition_PC1  Condition_PC2  Condition_PC3  \n",
       "0        -1.168980      -0.552511      -0.215972       0.326480  \n",
       "1        -1.161499      -0.552511      -0.215972       0.326480  \n",
       "2        -1.167042      -0.552511      -0.215972       0.326480  \n",
       "3        -1.816077      -0.552511      -0.215972       0.326480  \n",
       "4        -1.131358      -0.552511      -0.215972       0.326480  \n",
       "...            ...            ...            ...            ...  \n",
       "9905     -0.386364       0.126704       0.526293      -0.720117  \n",
       "9906     -0.645177      -0.552511      -0.215972       0.326480  \n",
       "9907      1.043960      -0.552511      -0.215972       0.326480  \n",
       "9908      1.213065      -0.552511      -0.215972       0.326480  \n",
       "9909     -2.226817      -0.552511      -0.215972       0.326480  \n",
       "\n",
       "[9910 rows x 105 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>Property_1</th>\n",
       "      <th>Property_2</th>\n",
       "      <th>Property_3</th>\n",
       "      <th>Property_4</th>\n",
       "      <th>Property_5</th>\n",
       "      <th>Property_6</th>\n",
       "      <th>Property_7</th>\n",
       "      <th>Property_8</th>\n",
       "      <th>Property_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Formula_PC29</th>\n",
       "      <th>Formula_PC30</th>\n",
       "      <th>Formula_PC31</th>\n",
       "      <th>Formula_PC32</th>\n",
       "      <th>Formula_PC33</th>\n",
       "      <th>Formula_PC34</th>\n",
       "      <th>Formula_PC35</th>\n",
       "      <th>Condition_PC1</th>\n",
       "      <th>Condition_PC2</th>\n",
       "      <th>Condition_PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630510</td>\n",
       "      <td>-1.044794</td>\n",
       "      <td>-1.010974</td>\n",
       "      <td>0.784127</td>\n",
       "      <td>-0.785801</td>\n",
       "      <td>0.434642</td>\n",
       "      <td>-1.168980</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626488</td>\n",
       "      <td>-1.039497</td>\n",
       "      <td>-1.011796</td>\n",
       "      <td>0.781721</td>\n",
       "      <td>-0.779595</td>\n",
       "      <td>0.437224</td>\n",
       "      <td>-1.161499</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.207747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.172320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625965</td>\n",
       "      <td>-1.040429</td>\n",
       "      <td>-1.009537</td>\n",
       "      <td>0.782721</td>\n",
       "      <td>-0.782244</td>\n",
       "      <td>0.433595</td>\n",
       "      <td>-1.167042</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944698</td>\n",
       "      <td>-0.966308</td>\n",
       "      <td>-1.208546</td>\n",
       "      <td>1.190928</td>\n",
       "      <td>-0.231057</td>\n",
       "      <td>1.037499</td>\n",
       "      <td>-1.816077</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>-0.445088</td>\n",
       "      <td>-1.135749</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.174548</td>\n",
       "      <td>1.176918</td>\n",
       "      <td>-1.131358</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>5507</td>\n",
       "      <td>0.253754</td>\n",
       "      <td>0.300485</td>\n",
       "      <td>0.247778</td>\n",
       "      <td>0.268624</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.368019</td>\n",
       "      <td>0.552818</td>\n",
       "      <td>0.244909</td>\n",
       "      <td>0.681583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>0.703369</td>\n",
       "      <td>-0.138177</td>\n",
       "      <td>0.232650</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>-0.055710</td>\n",
       "      <td>-0.386364</td>\n",
       "      <td>0.126704</td>\n",
       "      <td>0.526293</td>\n",
       "      <td>-0.720117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9906</th>\n",
       "      <td>5508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098897</td>\n",
       "      <td>1.631745</td>\n",
       "      <td>-0.126407</td>\n",
       "      <td>0.355267</td>\n",
       "      <td>0.879366</td>\n",
       "      <td>0.325944</td>\n",
       "      <td>-0.645177</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>5509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328240</td>\n",
       "      <td>-1.108290</td>\n",
       "      <td>0.176624</td>\n",
       "      <td>-1.003014</td>\n",
       "      <td>0.223545</td>\n",
       "      <td>-0.215317</td>\n",
       "      <td>1.043960</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>5510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233434</td>\n",
       "      <td>-0.102092</td>\n",
       "      <td>0.146241</td>\n",
       "      <td>-1.154091</td>\n",
       "      <td>0.553121</td>\n",
       "      <td>0.201320</td>\n",
       "      <td>1.213065</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>5511</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>0.132472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837051</td>\n",
       "      <td>0.871392</td>\n",
       "      <td>0.683864</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>0.622790</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.788210</td>\n",
       "      <td>-0.360862</td>\n",
       "      <td>-1.356307</td>\n",
       "      <td>0.766919</td>\n",
       "      <td>-1.876464</td>\n",
       "      <td>-1.106856</td>\n",
       "      <td>-2.226817</td>\n",
       "      <td>-0.552511</td>\n",
       "      <td>-0.215972</td>\n",
       "      <td>0.326480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9910 rows × 105 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8af618e803ebd04c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:37:10.491854Z",
     "start_time": "2025-09-18T03:36:41.713931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('datasets/Formula/processed_formula_property_data.csv')\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Expected columns: FID + 66 Properties + 35 Formula_PCs + 3 Condition_PCs = 105 columns\")\n",
    "print(f\"Actual columns: {len(data.columns)}\")\n",
    "\n",
    "# Check for the expected structure\n",
    "expected_properties = [f'Property_{i}' for i in range(1, 67)]\n",
    "expected_formula_features = [f'Formula_PC{i}' for i in range(1, 36)]\n",
    "expected_condition_features = [f'Condition_PC{i}' for i in range(1, 4)]\n",
    "\n",
    "properties_present = [col for col in expected_properties if col in data.columns]\n",
    "formula_features_present = [col for col in expected_formula_features if col in data.columns]\n",
    "condition_features_present = [col for col in expected_condition_features if col in data.columns]\n",
    "\n",
    "print(f\"\\nFound {len(properties_present)} properties out of 66 expected\")\n",
    "print(f\"Found {len(formula_features_present)} formula features out of 35 expected\")\n",
    "print(f\"Found {len(condition_features_present)} condition features out of 3 expected\")\n",
    "\n",
    "if 'FID' in data.columns:\n",
    "    print(\"FID column found\")\n",
    "else:\n",
    "    print(\"Warning: FID column not found\")\n",
    "\n",
    "print(f\"\\nSample of data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Analyze the dataset structure\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "class PropertyPredictor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.feature_columns = None\n",
    "        self.property_columns = None\n",
    "        self.models = {\n",
    "            'Random Forest': RandomForestRegressor(random_state=42),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "            'Support Vector Regression': SVR(),\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Ridge Regression': Ridge(random_state=42),\n",
    "            'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "            'K-Nearest Neighbors': KNeighborsRegressor()\n",
    "        }\n",
    "        self.results = {}\n",
    "\n",
    "    def identify_columns(self, feature_prefixes=None, property_prefixes=None):\n",
    "        \"\"\"\n",
    "        Identify feature and property columns based on prefixes\n",
    "        \"\"\"\n",
    "        if feature_prefixes is None or property_prefixes is None:\n",
    "            print(\"Error: Please specify feature_prefixes and property_prefixes\")\n",
    "            return\n",
    "\n",
    "        # Find columns matching the prefixes\n",
    "        feature_cols = [col for col in self.data.columns\n",
    "                        if any(col.startswith(prefix) for prefix in feature_prefixes)]\n",
    "        property_cols = [col for col in self.data.columns\n",
    "                         if any(col.startswith(prefix) for prefix in property_prefixes)]\n",
    "\n",
    "        # Sort the columns for better organization\n",
    "        feature_cols = sorted(feature_cols)\n",
    "        property_cols = sorted(property_cols, key=lambda x: int(x.split('_')[1]) if '_' in x else 0)\n",
    "\n",
    "        self.feature_columns = feature_cols\n",
    "        self.property_columns = property_cols\n",
    "\n",
    "        print(f\"Found {len(feature_cols)} feature columns:\")\n",
    "        print(f\"  Formula features: {len([c for c in feature_cols if 'Formula' in c])}\")\n",
    "        print(f\"  Condition features: {len([c for c in feature_cols if 'Condition' in c])}\")\n",
    "        print(f\"Found {len(property_cols)} property columns (Property_1 to Property_{len(property_cols)})\")\n",
    "\n",
    "        # Show sample of columns\n",
    "        print(f\"\\nSample feature columns: {feature_cols[:5]}...\")\n",
    "        print(f\"Sample property columns: {property_cols[:5]}...\")\n",
    "\n",
    "    def prepare_data_for_property(self, target_property):\n",
    "        \"\"\"\n",
    "        Prepare dataset for a specific property prediction (only non-NaN values)\n",
    "        \"\"\"\n",
    "        # Filter data where target property is not NaN\n",
    "        valid_data = self.data.dropna(subset=[target_property])\n",
    "\n",
    "        # Get features (drop rows where any feature is NaN)\n",
    "        X = valid_data[self.feature_columns].dropna()\n",
    "        y = valid_data.loc[X.index, target_property]\n",
    "\n",
    "        print(f\"\\nProperty: {target_property}\")\n",
    "        print(f\"Available samples: {len(X)} out of {len(self.data)}\")\n",
    "        print(f\"Feature shape: {X.shape}\")\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def evaluate_models(self, X, y, property_name):\n",
    "        \"\"\"\n",
    "        Evaluate multiple models for a given property\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        print(f\"\\nEvaluating models for {property_name}...\")\n",
    "        print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                # Create pipeline with scaling for models that need it\n",
    "                if name in ['Support Vector Regression', 'K-Nearest Neighbors']:\n",
    "                    pipeline = make_pipeline(StandardScaler(), model)\n",
    "                else:\n",
    "                    pipeline = model\n",
    "\n",
    "                # Train the model\n",
    "                pipeline.fit(X_train, y_train)\n",
    "\n",
    "                # Make predictions\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                # Calculate metrics\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                # Cross-validation score\n",
    "                cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5,\n",
    "                                            scoring='r2', n_jobs=-1)\n",
    "\n",
    "                results[name] = {\n",
    "                    'MSE': mse,\n",
    "                    'RMSE': rmse,\n",
    "                    'MAE': mae,\n",
    "                    'R2': r2,\n",
    "                    'CV_R2_mean': cv_scores.mean(),\n",
    "                    'CV_R2_std': cv_scores.std(),\n",
    "                    'model': pipeline,\n",
    "                    'predictions': y_pred,\n",
    "                    'y_test': y_test\n",
    "                }\n",
    "\n",
    "                print(\n",
    "                    f\"{name:25} - R2: {r2:.4f}, RMSE: {rmse:.4f}, CV R2: {cv_scores.mean():.4f}±{cv_scores.std():.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return results\n",
    "\n",
    "    def plot_results(self, results, property_name):\n",
    "        \"\"\"\n",
    "        Plot model comparison and predictions\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            print(\"No results to plot\")\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(f'Model Evaluation for {property_name}', fontsize=16)\n",
    "\n",
    "        # 1. Model comparison barplot\n",
    "        model_names = list(results.keys())\n",
    "        r2_scores = [results[name]['R2'] for name in model_names]\n",
    "        rmse_scores = [results[name]['RMSE'] for name in model_names]\n",
    "\n",
    "        axes[0, 0].barh(model_names, r2_scores)\n",
    "        axes[0, 0].set_xlabel('R² Score')\n",
    "        axes[0, 0].set_title('Model R² Comparison')\n",
    "        axes[0, 0].set_xlim(0, 1)\n",
    "\n",
    "        # 2. RMSE comparison\n",
    "        axes[0, 1].barh(model_names, rmse_scores)\n",
    "        axes[0, 1].set_xlabel('RMSE')\n",
    "        axes[0, 1].set_title('Model RMSE Comparison')\n",
    "\n",
    "        # 3. Best model predictions vs actual\n",
    "        best_model_name = max(results.keys(), key=lambda x: results[x]['R2'])\n",
    "        best_result = results[best_model_name]\n",
    "\n",
    "        axes[1, 0].scatter(best_result['y_test'], best_result['predictions'], alpha=0.6)\n",
    "        axes[1, 0].plot([best_result['y_test'].min(), best_result['y_test'].max()],\n",
    "                        [best_result['y_test'].min(), best_result['y_test'].max()], 'r--')\n",
    "        axes[1, 0].set_xlabel('Actual Values')\n",
    "        axes[1, 0].set_ylabel('Predicted Values')\n",
    "        axes[1, 0].set_title(f'Best Model: {best_model_name}\\nR² = {best_result[\"R2\"]:.4f}')\n",
    "\n",
    "        # 4. Residuals plot\n",
    "        residuals = best_result['y_test'] - best_result['predictions']\n",
    "        axes[1, 1].scatter(best_result['predictions'], residuals, alpha=0.6)\n",
    "        axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "        axes[1, 1].set_xlabel('Predicted Values')\n",
    "        axes[1, 1].set_ylabel('Residuals')\n",
    "        axes[1, 1].set_title('Residuals Plot')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return best_model_name, best_result\n",
    "\n",
    "    def hyperparameter_tuning(self, X, y, property_name, model_name='Random Forest'):\n",
    "        \"\"\"\n",
    "        Perform hyperparameter tuning for the best performing model\n",
    "        \"\"\"\n",
    "        print(f\"\\nPerforming hyperparameter tuning for {model_name}...\")\n",
    "\n",
    "        if model_name == 'Random Forest':\n",
    "            model = RandomForestRegressor(random_state=42)\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4]\n",
    "            }\n",
    "        elif model_name == 'Gradient Boosting':\n",
    "            model = GradientBoostingRegressor(random_state=42)\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 5, 7]\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Hyperparameter tuning not implemented for {model_name}\")\n",
    "            return None\n",
    "\n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=1\n",
    "        )\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best model evaluation\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Test R²: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "        return best_model, grid_search.best_params_\n",
    "\n",
    "    def feature_importance_analysis(self, model, feature_names, property_name):\n",
    "        \"\"\"\n",
    "        Analyze and plot feature importance\n",
    "        \"\"\"\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.title(f'Feature Importance for {property_name}')\n",
    "            plt.barh(range(len(importances)), importances[indices])\n",
    "            plt.yticks(range(len(importances)), [feature_names[i] for i in indices])\n",
    "            plt.xlabel('Importance')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Print top 10 features\n",
    "            print(f\"\\nTop 10 most important features for {property_name}:\")\n",
    "            for i in range(min(10, len(indices))):\n",
    "                idx = indices[i]\n",
    "                print(f\"{i + 1:2d}. {feature_names[idx]:30s} {importances[idx]:.4f}\")\n",
    "        else:\n",
    "            print(\"Model doesn't have feature importance attribute\")\n",
    "\n",
    "    def predict_all_properties(self):\n",
    "        \"\"\"\n",
    "        Run prediction pipeline for all properties\n",
    "        \"\"\"\n",
    "        if self.property_columns is None:\n",
    "            print(\"Please run identify_columns() first\")\n",
    "            return\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        for property_name in self.property_columns:\n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"PROCESSING PROPERTY: {property_name}\")\n",
    "            print(f\"{'=' * 60}\")\n",
    "\n",
    "            try:\n",
    "                # Prepare data\n",
    "                X, y = self.prepare_data_for_property(property_name)\n",
    "\n",
    "                if len(X) < 10:  # Skip if too few samples\n",
    "                    print(f\"Skipping {property_name} - insufficient samples ({len(X)})\")\n",
    "                    continue\n",
    "\n",
    "                # Evaluate models\n",
    "                results = self.evaluate_models(X, y, property_name)\n",
    "\n",
    "                # Plot results\n",
    "                best_model_name, best_result = self.plot_results(results, property_name)\n",
    "\n",
    "                # Feature importance for tree-based models\n",
    "                if hasattr(best_result['model'], 'feature_importances_'):\n",
    "                    self.feature_importance_analysis(\n",
    "                        best_result['model'], self.feature_columns, property_name\n",
    "                    )\n",
    "\n",
    "                # Store results\n",
    "                all_results[property_name] = {\n",
    "                    'results': results,\n",
    "                    'best_model': best_model_name,\n",
    "                    'best_score': best_result['R2']\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {property_name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Summary\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(\"SUMMARY\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        for prop, info in all_results.items():\n",
    "            print(f\"{prop:30s} - Best: {info['best_model']:20s} (R² = {info['best_score']:.4f})\")\n",
    "\n",
    "    def predict_specific_properties(self, property_list):\n",
    "        \"\"\"\n",
    "        Run prediction pipeline for specific properties only\n",
    "        \"\"\"\n",
    "        if self.property_columns is None:\n",
    "            print(\"Please run identify_columns() first\")\n",
    "            return\n",
    "\n",
    "        # Filter to only requested properties that exist\n",
    "        valid_properties = [prop for prop in property_list if prop in self.property_columns]\n",
    "        invalid_properties = [prop for prop in property_list if prop not in self.property_columns]\n",
    "\n",
    "        if invalid_properties:\n",
    "            print(f\"Warning: These properties not found: {invalid_properties}\")\n",
    "\n",
    "        if not valid_properties:\n",
    "            print(\"No valid properties found\")\n",
    "            return\n",
    "\n",
    "        print(f\"Processing {len(valid_properties)} properties: {valid_properties}\")\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for property_name in valid_properties:\n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"PROCESSING PROPERTY: {property_name}\")\n",
    "            print(f\"{'=' * 60}\")\n",
    "\n",
    "            try:\n",
    "                # Prepare data\n",
    "                X, y = self.prepare_data_for_property(property_name)\n",
    "\n",
    "                if len(X) < 10:  # Skip if too few samples\n",
    "                    print(f\"Skipping {property_name} - insufficient samples ({len(X)})\")\n",
    "                    continue\n",
    "\n",
    "                # Evaluate models\n",
    "                property_results = self.evaluate_models(X, y, property_name)\n",
    "\n",
    "                # Plot results\n",
    "                best_model_name, best_result = self.plot_results(property_results, property_name)\n",
    "\n",
    "                # Feature importance for tree-based models\n",
    "                if hasattr(best_result['model'], 'feature_importances_'):\n",
    "                    self.feature_importance_analysis(\n",
    "                        best_result['model'], self.feature_columns, property_name\n",
    "                    )\n",
    "\n",
    "                # Store results\n",
    "                results[property_name] = {\n",
    "                    'results': property_results,\n",
    "                    'best_model': best_model_name,\n",
    "                    'best_score': best_result['R2']\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {property_name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Summary\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(\"SUMMARY\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        for prop, info in results.items():\n",
    "            print(f\"{prop:15s} - Best: {info['best_model']:20s} (R² = {info['best_score']:.4f})\")\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = PropertyPredictor(data)\n",
    "\n",
    "# Identify feature and property columns\n",
    "# Identify columns based on your specific structure\n",
    "feature_prefixes = ['Formula_PC', 'Condition_PC']  # Features are Formula_PC* and Condition_PC*\n",
    "property_prefixes = ['Property_']  # Properties are Property_*\n",
    "predictor.identify_columns(feature_prefixes, property_prefixes)\n",
    "\n",
    "# Run prediction for all properties\n",
    "results = predictor.predict_all_properties()\n",
    "\n",
    "# Optional: Detailed analysis for a specific property (e.g., Property_1)\n",
    "specific_property = 'Property_1'  # You can change this to any Property_X\n",
    "print(f\"\\nDetailed analysis for: {specific_property}\")\n",
    "\n",
    "if specific_property in predictor.property_columns:\n",
    "    X, y = predictor.prepare_data_for_property(specific_property)\n",
    "    if len(X) > 10:  # Only proceed if enough samples\n",
    "        results_detailed = predictor.evaluate_models(X, y, specific_property)\n",
    "\n",
    "        # Hyperparameter tuning for best model\n",
    "        best_model_name = max(results_detailed.keys(), key=lambda x: results_detailed[x]['R2'])\n",
    "        best_model, best_params = predictor.hyperparameter_tuning(X, y, specific_property, best_model_name)\n",
    "    else:\n",
    "        print(f\"Insufficient samples for {specific_property}\")\n",
    "else:\n",
    "    print(f\"{specific_property} not found in property columns\")\n",
    "\n",
    "\n",
    "# Data exploration and correlation analysis\n",
    "def explore_data(data, property_columns, feature_columns):\n",
    "    \"\"\"\n",
    "    Explore the dataset and show correlations\n",
    "    \"\"\"\n",
    "    print(\"Data Exploration:\")\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"Total features: {len(feature_columns)}\")\n",
    "    print(f\"Total properties: {len(property_columns)}\")\n",
    "\n",
    "    # Correlation matrix for properties\n",
    "    if len(property_columns) > 1:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        correlation_matrix = data[property_columns].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Property Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Distribution of each property\n",
    "    fig, axes = plt.subplots((len(property_columns) + 2) // 3, 3,\n",
    "                             figsize=(15, 5 * ((len(property_columns) + 2) // 3)))\n",
    "    axes = axes.flatten() if len(property_columns) > 1 else [axes]\n",
    "\n",
    "    for i, prop in enumerate(property_columns):\n",
    "        if i < len(axes):\n",
    "            data[prop].dropna().hist(bins=30, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribution of {prop}')\n",
    "            axes[i].set_xlabel(prop)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(property_columns), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run data exploration\n",
    "explore_data(data, predictor.property_columns, predictor.feature_columns)\n",
    "\n",
    "# Check property data availability\n",
    "property_stats = predictor.get_property_statistics()\n",
    "\n",
    "# Example: Predict only first 10 properties\n",
    "first_10_properties = [f'Property_{i}' for i in range(1, 11)]\n",
    "results_subset = predictor.predict_specific_properties(first_10_properties)\n",
    "\n",
    "# Example: Focus on specific properties of interest\n",
    "# properties_of_interest = ['Property_1', 'Property_5', 'Property_10', 'Property_15']\n",
    "# results_specific = predictor.predict_specific_properties(properties_of_interest)\n",
    "\n",
    "print(\"\\nPipeline completed! Check the results and plots above.\")\n",
    "print(\"\\nQuick tips:\")\n",
    "print(\"- Use predict_all_properties() to process all 66 properties (may take time)\")\n",
    "print(\"- Use predict_specific_properties([list]) to focus on specific properties\")\n",
    "print(\"- Use get_property_statistics() to see data availability\")\n",
    "print(\"- Check the feature importance plots to understand what drives each property\")"
   ],
   "id": "7ed1c0442f93a34a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9910, 105)\n",
      "Expected columns: FID + 66 Properties + 35 Formula_PCs + 3 Condition_PCs = 105 columns\n",
      "Actual columns: 105\n",
      "\n",
      "Found 66 properties out of 66 expected\n",
      "Found 35 formula features out of 35 expected\n",
      "Found 3 condition features out of 3 expected\n",
      "FID column found\n",
      "\n",
      "Sample of data:\n",
      "   FID  Property_1  Property_2  Property_3  Property_4  Property_5  \\\n",
      "0    1         NaN         NaN    0.187732         NaN         NaN   \n",
      "1    2         NaN         NaN    0.167026         NaN         NaN   \n",
      "2    3         NaN         NaN    0.207747         NaN         NaN   \n",
      "3    4         NaN         NaN    0.318178         NaN         NaN   \n",
      "4    5         NaN         NaN    0.314727         NaN         NaN   \n",
      "\n",
      "   Property_6  Property_7  Property_8  Property_9  ...  Formula_PC29  \\\n",
      "0         NaN    0.192958         NaN         NaN  ...      0.630510   \n",
      "1         NaN    0.178770         NaN         NaN  ...      0.626488   \n",
      "2         NaN    0.172320         NaN         NaN  ...      0.625965   \n",
      "3         NaN    0.430285         NaN         NaN  ...      0.944698   \n",
      "4         NaN    0.418935         NaN         NaN  ...      0.962751   \n",
      "\n",
      "   Formula_PC30  Formula_PC31  Formula_PC32  Formula_PC33  Formula_PC34  \\\n",
      "0     -1.044794     -1.010974      0.784127     -0.785801      0.434642   \n",
      "1     -1.039497     -1.011796      0.781721     -0.779595      0.437224   \n",
      "2     -1.040429     -1.009537      0.782721     -0.782244      0.433595   \n",
      "3     -0.966308     -1.208546      1.190928     -0.231057      1.037499   \n",
      "4     -0.445088     -1.135749      0.909521      0.174548      1.176918   \n",
      "\n",
      "   Formula_PC35  Condition_PC1  Condition_PC2  Condition_PC3  \n",
      "0     -1.168980      -0.552511      -0.215972        0.32648  \n",
      "1     -1.161499      -0.552511      -0.215972        0.32648  \n",
      "2     -1.167042      -0.552511      -0.215972        0.32648  \n",
      "3     -1.816077      -0.552511      -0.215972        0.32648  \n",
      "4     -1.131358      -0.552511      -0.215972        0.32648  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9910 entries, 0 to 9909\n",
      "Columns: 105 entries, FID to Condition_PC3\n",
      "dtypes: float64(104), int64(1)\n",
      "memory usage: 7.9 MB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "FID                 0\n",
      "Property_1       6136\n",
      "Property_2       6163\n",
      "Property_3       5932\n",
      "Property_4       6179\n",
      "                 ... \n",
      "Formula_PC34        0\n",
      "Formula_PC35        0\n",
      "Condition_PC1       0\n",
      "Condition_PC2       0\n",
      "Condition_PC3       0\n",
      "Length: 105, dtype: int64\n",
      "Found 38 feature columns:\n",
      "  Formula features: 35\n",
      "  Condition features: 3\n",
      "Found 66 property columns (Property_1 to Property_66)\n",
      "\n",
      "Sample feature columns: ['Condition_PC1', 'Condition_PC2', 'Condition_PC3', 'Formula_PC1', 'Formula_PC10']...\n",
      "Sample property columns: ['Property_1', 'Property_2', 'Property_3', 'Property_4', 'Property_5']...\n",
      "\n",
      "============================================================\n",
      "PROCESSING PROPERTY: Property_1\n",
      "============================================================\n",
      "\n",
      "Property: Property_1\n",
      "Available samples: 3774 out of 9910\n",
      "Feature shape: (3774, 38)\n",
      "\n",
      "Evaluating models for Property_1...\n",
      "Training samples: 3019, Test samples: 755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37738412f35e2545"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
